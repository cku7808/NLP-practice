{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSlbstf8wym1sHktq1DjlH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cku7808/NLP-practice/blob/main/N_gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **N-gram**"
      ],
      "metadata": {
        "id": "KSGHBQgzoXlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**단어의 등장 순서를 고려하는 빈도 수 기반의 단어 표현 방법**  \n",
        "**문장을 n개의 word/character를 한 단위로 토큰화 하는 것**"
      ],
      "metadata": {
        "id": "u12z2Q5XoiRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "N-gram 만들기  \n",
        "1. n 설정\n",
        "2. n개의 word/character를 한 단위로 토큰화\n",
        "3. 등장 빈도 수에 따른 벡터 생성"
      ],
      "metadata": {
        "id": "2TryxBJ7pFr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제 1) An adorable little boy is spreading smiles"
      ],
      "metadata": {
        "id": "yMin7_qiqDEc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5OZMb8obm5w5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7c4b3d-31a1-4b22-9341-81b9b68ca1e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-gram(unigram) : ['A', 'n', ' ', 'a', 'd', 'o', 'r', 'a', 'b', 'l', 'e', ' ', 'l', 'i', 't', 't', 'l', 'e', ' ', 'b', 'o', 'y', ' ', 'i', 's', ' ', 's', 'p', 'r', 'e', 'a', 'd', 'i', 'n', 'g', ' ', 's', 'm', 'i', 'l', 'e', 's']\n",
            "2-gram(bigram) : ['An', 'n ', ' a', 'ad', 'do', 'or', 'ra', 'ab', 'bl', 'le', 'e ', ' l', 'li', 'it', 'tt', 'tl', 'le', 'e ', ' b', 'bo', 'oy', 'y ', ' i', 'is', 's ', ' s', 'sp', 'pr', 're', 'ea', 'ad', 'di', 'in', 'ng', 'g ', ' s', 'sm', 'mi', 'il', 'le', 'es']\n",
            "3-gram(trigram) : ['An ', 'n a', ' ad', 'ado', 'dor', 'ora', 'rab', 'abl', 'ble', 'le ', 'e l', ' li', 'lit', 'itt', 'ttl', 'tle', 'le ', 'e b', ' bo', 'boy', 'oy ', 'y i', ' is', 'is ', 's s', ' sp', 'spr', 'pre', 'rea', 'ead', 'adi', 'din', 'ing', 'ng ', 'g s', ' sm', 'smi', 'mil', 'ile', 'les']\n",
            "4-gram : ['An a', 'n ad', ' ado', 'ador', 'dora', 'orab', 'rabl', 'able', 'ble ', 'le l', 'e li', ' lit', 'litt', 'ittl', 'ttle', 'tle ', 'le b', 'e bo', ' boy', 'boy ', 'oy i', 'y is', ' is ', 'is s', 's sp', ' spr', 'spre', 'prea', 'read', 'eadi', 'adin', 'ding', 'ing ', 'ng s', 'g sm', ' smi', 'smil', 'mile', 'iles']\n"
          ]
        }
      ],
      "source": [
        "sentence = \"An adorable little boy is spreading smiles\"\n",
        "\n",
        "def N_gram(n,sent):\n",
        "  result = []\n",
        "  for i in range(len(sent)-(n-1)):\n",
        "    result.append(sent[i:i+n])\n",
        "  return result\n",
        "\n",
        "print(\"1-gram(unigram) :\",N_gram(1,sentence))\n",
        "print(\"2-gram(bigram) :\",N_gram(2,sentence))\n",
        "print(\"3-gram(trigram) :\",N_gram(3,sentence))\n",
        "print(\"4-gram :\",N_gram(4,sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# n-gram의 한계\n",
        "출처 : 위키독스 딥러닝을 이용한 자연어 처리 입문  \n",
        "  \n",
        "만약 갖고있는 코퍼스에서 boy is spreading가 1,000번 등장했다고 한다면,  \n",
        "그리고 boy is spreading insults가 500번 등장했으며, boy is spreading smiles가 200번 등장했다고 가정.  \n",
        "그렇게 되면 boy is spreading 다음에 insults가 등장할 확률은 50%이며, smiles가 등장할 확률은 20%.  \n",
        "확률적 선택에 따라 우리는 insults가 더 맞다고 판단하게 된다.  \n",
        "그러나 문장 앞의 \"an adorable little\"이라는 수식어가 반영되지 않았음 -> 만약 이 수식어가 반영된 상황에서 둘 중 하나를 선택한다면 전자를 선택할까?  \n",
        "**-> 문장 전체의 맥락을 반영할 수 없다는 한계**"
      ],
      "metadata": {
        "id": "GgAXERsncuOi"
      }
    }
  ]
}